---
title: "Ejercicio 3 - Práctico 2"
author: "Valentina Caldiroli"
date: "Modelos lineales"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(car)
```
Para comenzar con el analisis de los datos, lo primero será cargarlos:

```{r, echo = FALSE}
datos <- read.table("Tabla 7.3.txt")
datos <- datos %>% filter(V1 != 'y')
y <- as.numeric(datos$V1)
x1 <- as.numeric(datos$V2)
x2 <- as.numeric(datos$V3)
x3 <- as.numeric(datos$V4)
x4 <- as.numeric(datos$V5)
datos <-data.frame(y =y, x1 = x1, x2 = x2, x3 = x3, x4= x4)
```

## Parte a:

Por letra, podemos plantear el modelo de regresión lineal como
 
 $$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3+ \beta_4 x_4$$
 
 De donde se sabe:
 
 $y$ = Cantidad de vapor
 
 $x_1$ = Temperatura del tanque
 
 $x_2$ = Temperatura de la gasolina
 
 $x_3$ = Presión del vapor del tanque
 
 $x_4$ = Presión del vapor de la gasolina
 
 Entonces para poder hallar los estimadores $\beta_i$ por el método de mínimos cuadrados usamos la función $lm()$, que nos modeliza los datos, y luego con la función $coef()$ del modelo obtenemos los coeficientes $\beta_i$ que buscábamos, que es igual a la matriz b, entonces podemos llamar b al resultado que nos da $coef()$.
 
```{r}
modelo <- lm(y~x1+x2+x3+x4, datos)
b <- coef(modelo)
b
```
 
 Entonces nos queda un modelo con la siguiente forma:

$$ y = 1.015 - 0.028x_1 +0.215x_2 -4.32x_3 +8.974x_4$$


Debemos calcular también $\sigma^2$, que tiene la forma:

$$\sigma^2 = \frac{SCR}{n-k-1}$$ 

$SCR$ está definido como la suma de los cuadrados residuales, que podemos calcularlo como:

```{r}
residuos <- residuals(modelo)
SCR <- sum(residuos^2)
SCR
```

Sabiendo que $n=32~ número~de~observaciones$, $k=4,~ número~ de~ variables~ explicativas$, podemos entonces plantear 

$$\sigma^2 = \frac{201.2361}{32-4-1}$$

```{r}
sigma2 <- SCR/df.residual(modelo)
sigma2
```
Entonces:

$$\sigma^2 = 7.453$$

## Parte b:

Como sabemos b = a la matriz de los $\beta_i$. Que ya la tenemos calculada, podemos entonces elevar al cuadrado los errores estándar del resumen del modelo que lo obtenemos con la función $summary()$.

```{r}
summary(modelo)
```

```{r}
2.73^2
```


Obtenemos que $Var(b) = 2.73^2 =7.4529$.

## Parte c:

Para obetner el $R^2$ y el $R_{aj}^2$ podemos aplicar la función $summary()$ al modelo que estimamos con $lm()$, resumen que ya tenemos del punto anterior y nos brinda los siguientes resultados.

Entonces obtuvimos como resultado que $R^2=0.9261$ y $R_{aj}2=0.9151$. 

## Parte d:

Para realizar el test de significación del modelo, lo que debemos hacer es el siguiente planteo para el contraste de hipótesis:

$$H_0) \beta_1 = \beta_2 = \beta_3 = \beta_4 = 0 \\ H_1)  \beta_1 \neq \beta_2 \neq \beta_3 \neq \beta_4 \neq 0$$

Para obtener la significación se utilizarán datos brindados en el $summary(modelo)$, observandp e $p-valor$ y los estadísticos F.

Este summary nos devuelve un $p-valor = 7.249e-15$, con un estadístico F del modelo igual a 84.54. Analizando lo pequeño que es el p-valor, podemos concluir que tanto a un 5%, como a un 10%, el modelo es significativo, es decir que en su conjunto las variables logran explicar a $y$.

## Parte e:

Para realizar ese test, también usarmos la función $lm()$

```{r}
modelo1 <- lm(y ~x1+x3, datos)
summary(modelo1)
```

En este caso el modelo sigue siendo significativo a un 5%, dado que el $p-valor = 1.235e-09$, menor a $\alpha = 0.05$

## Parte f:

Para analizar una hipótesis tal como $H_0) \beta_j = 0~~\forall~j = 1,2,3,4$, podemos utilizar el mismo $summary(modelo)$ que en la parte d. Se analiza cada regló comparando los p-valores. Observamos entonces que solo $x2$ y $x4$ son significativas al 5%.

## Parte g:

La construccipon de los intervalos de confianza al $(1-\alpha)\%$, puede hacerse con la función $confint(modelo)$, de donde podemos añadir el nivel de confianza al que se quiere trabajar con el argumento $level$, por defecto trabaja con $\alpha=0.05$.


```{r}
confint(modelo)
```

Nos devuelve entonces el intervalo de confianza al 95% para cada $\beta_i$, esto indica que:

$\beta_0$ se encuentra entre $[-2.8040;~ 4.8341]$ con un 95% de confianza.

$\beta_1$ se encuentra entre $[-0.2145;~ 0.1572]$ con un 95% de confianza.

$\beta_2$ se encuentra entre $[0.0768;~ 0.3547]$ con un 95% de confianza.

$\beta_3$ se encuentra entre $[-10.1697;~ 1.5296]$ con un 95% de confianza.

$\beta_4$ se encuentra entre $[3.2859;~ 14.6638]$ con un 95% de confianza.


## Parte h: 

Para trabajar en esta parte, utilizaremos una función de la librería $car$, llamada $linearHypothesis()$, que nos permitirá testear otras hipótesis nulas, y se observan a continuación:

* $H_0)~~ \beta_1 = \beta_2 = \frac{\beta_3}{12} = \frac{\beta_4}{12}$

```{r}
A <- matrix(c(0,1,-1,1/12,-1/12), ncol=5)
linearHypothesis(modelo, A, test = 'F')
```

Obtuvimos entonces un $p-valor=0.0015$, lo cual nos indica que bajo esta hipotesis el modelo es significativo al 5%. 

* $H_0)~~\beta_1 = \beta_2$

```{r}
A <- matrix(c(0,1,-1,0,0), ncol=5)
linearHypothesis(modelo, A, test = 'F')
```

En este caso, obtuvimos un $p-valor =0.0689$, hablamos entonces de un contraste no significativo al 5%, puede serlo al 10%.

* $H_0)~~\beta_2 = \frac{\beta_3}{12}$

```{r}
A <- matrix(c(0,0,1,12*(-1/12),0), ncol =5)
linearHypothesis(modelo, A, test = 'F')
```

Acá el $p-valor = 0.0118$, por lo que este contraste de hipótesis no es significativo al 5%, tampoco lo es al 10%.

* $H_0)~~\beta_3 = \beta_4$

```{r}
A <- matrix(c(0,0,0,1,-1), ncol=5)
linearHypothesis(modelo, A, test = 'F')
```

En este caso, el $p-valor = 0.02261$ también el modelo es significaivo al 5% para este contraste. 

* $H_0)~~\beta_1=\beta_2$ y $\beta_3=\beta_4$

```{r}
A <- matrix(c(0,1,-1,0,0,0,0,0,1,-1), nrow = 2)
linearHypothesis(modelo, A, test = 'F')
```

Habalmos de un $p-valor = 0.01081$, por lo que el modelo es significativo al 5%, donde en realidad lo que testeamos es que todos los $beta_i$ son iguales entre sí.